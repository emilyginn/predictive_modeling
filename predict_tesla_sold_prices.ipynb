{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee02838",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf630e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f608324",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0815f65",
   "metadata": {},
   "source": [
    "## Import Tesla Data From S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c990a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "## specify the S3 object keys\n",
    "bucket_name = 'tesla-project'\n",
    "file_keys = ['data/tesla_used_car_sold-2022-05.csv', \n",
    "             'data/tesla_used_car_sold-2022-06.csv',\n",
    "             'data/tesla_used_car_sold-2022-07.csv', \n",
    "             'data/tesla_used_car_sold-2022-08.csv']\n",
    "\n",
    "## read the S3 objects and concatenate into a single dataframe\n",
    "dfs = []\n",
    "for file_key in file_keys:\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    dfs.append(pd.read_csv(obj['Body']))\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df158a5a",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c1281",
   "metadata": {},
   "source": [
    "#### Vehicle Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform one hot encoding on each of the vehicle features in the 'features' column\n",
    "df = pd.concat([df, pd.get_dummies(df['features'].str.split(';').apply(pd.Series).stack()).groupby(level=0).sum()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove 'Model S', 'Model X', 'Model 3', 'Model Y' prefixes from trim values\n",
    "df['trim'] = df['trim'].str.replace('Model S ', '').str.replace('Model X ', '').str.replace('Model 3 ', '').str.replace('Model Y ', '')\n",
    "\n",
    "## Perform one hot encoding for the trim\n",
    "df = pd.concat([df, pd.get_dummies(df['trim']).astype('int')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6004fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform one hot encoding for the vehicle model\n",
    "df = pd.concat([df, pd.get_dummies(df['model']).astype('int')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28b5de",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the city from the location column and saving it in title case\n",
    "df['location'] = df['location'].str.split(',').str[0].str.title()\n",
    "\n",
    "## Dropping rows with missing locations\n",
    "df = df.loc[~df['state'].isna()]\n",
    "\n",
    "## Fill nulls for metro area\n",
    "df['metro'].fillna('No Metro', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad7f58",
   "metadata": {},
   "source": [
    "#### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert date to days since epoch\n",
    "df['sold_date'] = pd.to_datetime(df['sold_date'])\n",
    "df['daysSinceEpoch'] = (df['sold_date'] - pd.Timestamp(\"1970-01-01\")).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0d119",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the metro column\n",
    "df['metro_label'] = le.fit_transform(df['metro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the location column\n",
    "df['location_label'] = le.fit_transform(df['location'])\n",
    "\n",
    "# Concatenate the location and state columns with a hyphen\n",
    "df['location_state'] = df['location'] + '-' + df['state']\n",
    "\n",
    "# Encode the location_state column\n",
    "df['location_state_label'] = le.fit_transform(df['location_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f4395",
   "metadata": {},
   "source": [
    "### Add Calculated Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the age of the vehicle in years\n",
    "df['vehicle_age'] = (df['sold_date'].dt.year - df['year']).apply(lambda x: max(x,1))\n",
    "\n",
    "# Calculate miles per year\n",
    "df['miles_per_year'] = df['miles'] // df['vehicle_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ad722",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the zScore of the mileage\n",
    "df['mileage_zscore'] = stats.zscore(df['miles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de6076",
   "metadata": {},
   "source": [
    "### Import Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import lookup table from s3 and save in a dataframe\n",
    "obj = s3.get_object(Bucket=bucket_name, Key='data/tesla_project_economic_indicator_data.csv')\n",
    "lookup = pd.read_csv(obj['Body'])\n",
    "lookup.drop(columns='Year', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e10683",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d801022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(lookup, left_on = df.sold_date.dt.month, right_on = lookup.Month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d763462",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30933359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by model and sold date, and calculate the mean sold price per week\n",
    "grouped_df = df.groupby([\"model\", pd.Grouper(key=\"sold_date\", freq=\"W\")])[\"sold_price\"].mean().reset_index()\n",
    "\n",
    "# pivot data to have models as columns\n",
    "pivoted_df = grouped_df.pivot(index=\"sold_date\", columns=\"model\", values=\"sold_price\")\n",
    "\n",
    "# plot time series\n",
    "pivoted_df.plot(figsize=(10, 6))\n",
    "plt.title(\"Average Tesla Model Prices By Week\")\n",
    "plt.xlabel(\"Sold Date\")\n",
    "plt.ylabel(\"Sold Price\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by model and sold_date, resampled to weekly frequency, and count the number of sales\n",
    "weekly_sales = df.groupby(['model', pd.Grouper(key='sold_date', freq='W')]).count().reset_index()\n",
    "\n",
    "# Pivot the table to have models as columns and the count of sales as values\n",
    "weekly_sales_pivot = weekly_sales.pivot(index='sold_date', columns='model', values='sold_price')\n",
    "\n",
    "# Plot the counts of each Tesla model sold over time\n",
    "weekly_sales_pivot.plot(kind='line', figsize=(10,5))\n",
    "plt.title('Counts of Tesla Models Sold By Week')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27896bcd",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f6043",
   "metadata": {},
   "source": [
    "#### Final Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52837ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['vin', 'location', 'state', 'metro', 'location_state', 'location_label', 'color', 'interior', 'wheels', 'features', 'country', 'currency', 'trim', 'model', 'sold_date', 'key_0', 'Month', '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = [column for column in df.columns.to_list() if column not in columns_to_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df[model_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa006d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405cc0b",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.drop('sold_price', axis=1)\n",
    "y = model_df['sold_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522b096",
   "metadata": {},
   "source": [
    "## Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc459e7",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean absolute error on the test set\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "print('Mean Absolute Error:', mae_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = rf_model.feature_importances_\n",
    "\n",
    "sorted_idx = np.argsort(important_feats)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, important_feats[sorted_idx], align='center')\n",
    "plt.yticks(pos, X_test.columns[sorted_idx])\n",
    "plt.ylim([len(X_train.columns)-25, len(X_train.columns)])\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8877b0",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=7)\n",
    "\n",
    "# Train model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate mean absolute error\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(\"Mean Absolute Error:\", mae_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = xgb_model.feature_importances_\n",
    "\n",
    "sorted_idx = np.argsort(important_feats)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, important_feats[sorted_idx], align='center')\n",
    "plt.yticks(pos, X_test.columns[sorted_idx])\n",
    "plt.ylim([len(X_train.columns)-25, len(X_train.columns)])\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2217ec07",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0461fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "gbr = GradientBoostingRegressor(loss='absolute_error', learning_rate=0.1, n_estimators=100, max_depth=7, random_state=42)\n",
    "\n",
    "# fit the model to the training data\n",
    "gbr_model = gbr.fit(X_train, y_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred_gbr = gbr_model.predict(X_test)\n",
    "\n",
    "# calculate mean absolute error\n",
    "mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
    "print(\"Mean Absolute Error:\", mae_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feats = gbr_model.feature_importances_\n",
    "\n",
    "sorted_idx = np.argsort(important_feats)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, important_feats[sorted_idx], align='center')\n",
    "plt.yticks(pos, X_test.columns[sorted_idx])\n",
    "plt.ylim([len(X_train.columns)-25, len(X_train.columns)])\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa09d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
